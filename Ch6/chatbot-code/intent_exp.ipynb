{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "intent_exp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishkalavallabhi/practicalnlp/blob/V_2_0/Ch6/chatbot-code/intent_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LvnO8gwHbwI",
        "colab_type": "text"
      },
      "source": [
        "# Intent Recognition with Sequential Models and Word2Vec\n",
        "The goal of this notebook will be to classify intents of sentences. <br>For the purpose of demonstration, we will be using the ATIS (Airline travel information system) dataset. \n",
        "This can be accomplished with the following steps:\n",
        "- Reading the dataset (from iob files) and Understanding the labels\n",
        "- Encoding the intent labels\n",
        "- Loading the word2vec model and embedding the words.\n",
        "- Creating our sequential model (Bi-RNN) with PyTorch\n",
        "- Testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF99WLdnHbwO",
        "colab_type": "text"
      },
      "source": [
        "## Reading the dataset and Understanding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYYQ20AEQDM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8yxwVQ8JXur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_data(filename):\n",
        "    df = pd.read_csv(filename,delim_whitespace=True,names=['word','label'])\n",
        "    beg_indices = list(df[df['word'] == 'BOS'].index)+[df.shape[0]]\n",
        "    sents,labels,intents = [],[],[]\n",
        "    for i in range(len(beg_indices[:-1])):\n",
        "        sents.append(df[beg_indices[i]+1:beg_indices[i+1]-1]['word'].values)\n",
        "        labels.append(df[beg_indices[i]+1:beg_indices[i+1]-1]['label'].values)\n",
        "        intents.append(df.loc[beg_indices[i+1]-1]['label'])    \n",
        "    return np.array(sents),np.array(labels),np.array(intents)\n",
        "\n",
        "def get_data2(filename):\n",
        "    print (filename)\n",
        "    with open(filename) as f:\n",
        "        contents = f.read()\n",
        "    sents,labels,intents = [],[],[]\n",
        "    for line in contents.strip().split('\\n'):\n",
        "        words,labs = [i.split(' ') for i in line.split('\\t')]\n",
        "        sents.append(words[1:-1])\n",
        "        labels.append(labs[1:-1])\n",
        "        intents.append(labs[-1])\n",
        "    return np.array(sents),np.array(labels),np.array(intents)\n",
        "\n",
        "read_method = {'/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis-2.dev.w-intent.iob':get_data,\n",
        "               '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob':get_data2,\n",
        "               '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.test.w-intent.iob':get_data,\n",
        "              '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis-2.train.w-intent.iob':get_data2}\n",
        "\n",
        "def fetch_data(fname):\n",
        "    func = read_method[fname]\n",
        "    return func(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hGOXeeOJ7Zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e03a5d3a-fc7a-41e6-edca-1795a0fea191"
      },
      "source": [
        "read_method "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis-2.dev.w-intent.iob': <function __main__.get_data>,\n",
              " '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis-2.train.w-intent.iob': <function __main__.get_data2>,\n",
              " '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.test.w-intent.iob': <function __main__.get_data>,\n",
              " '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob': <function __main__.get_data2>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr69mNBXQ6Lg",
        "colab_type": "code",
        "outputId": "ec0f9c6c-fefe-45ab-b357-f0464744c825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_vNM0CXHbwW",
        "colab_type": "code",
        "outputId": "f7614845-fd6e-4d39-ce49-75adcf3e4840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "#from utils import fetch_data, read_method\n",
        "\n",
        "sents,labels,intents = fetch_data('/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob')\n",
        "\n",
        "def display(n):\n",
        "    sense = []\n",
        "    print (\"INTENT : \",intents[n])\n",
        "    for i in range(len(sents[n])):\n",
        "    #     sense.append({\"word_index\":word_indices[0][i],\"word\":words2idx[word_indices[0][i]],\"entity_index\":name_entities[0][i],\"entity\":tables2idx[name_entities[0][i]],\"label_index\":labels[0][i],\"label\":labels2idx[labels[0][i]]})\n",
        "        sense.append({\"word\":sents[n][i],\"label\":labels[n][i]})\n",
        "    return pd.DataFrame(sense)\n",
        "\n",
        "print (\"Number of sentences :\",len(sents))\n",
        "print (\"Number of unique intents :\",len(set(intents)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob\n",
            "Number of sentences : 4978\n",
            "Number of unique intents : 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_bwxkdvHbwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "d7400654-f37f-42dd-b585-1f5dbd9f1fa7"
      },
      "source": [
        "# sents - List of sentences where each sentence is a list of words\n",
        "# intents - List of labelled intents\n",
        "display(random.randint(0,len(sents)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INTENT :  atis_flight\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-class_type</td>\n",
              "      <td>coach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-economy</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I-economy</td>\n",
              "      <td>class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-depart_time.period_of_day</td>\n",
              "      <td>night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>O</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>O</td>\n",
              "      <td>from</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>B-fromloc.city_name</td>\n",
              "      <td>boston</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>O</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B-toloc.city_name</td>\n",
              "      <td>san</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I-toloc.city_name</td>\n",
              "      <td>francisco</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          label       word\n",
              "0                             O       what\n",
              "1                             O         is\n",
              "2                             O        the\n",
              "3                  B-class_type      coach\n",
              "4                     B-economy    economy\n",
              "5                     I-economy      class\n",
              "6   B-depart_time.period_of_day      night\n",
              "7                             O    service\n",
              "8                             O       from\n",
              "9           B-fromloc.city_name     boston\n",
              "10                            O         to\n",
              "11            B-toloc.city_name        san\n",
              "12            I-toloc.city_name  francisco"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf0ZqWW1Hbwn",
        "colab_type": "text"
      },
      "source": [
        "## ~~Loading~~ Training the word2vec model and embedding the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHNdKp6eHbwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0df82ce-c3ef-4898-c9cd-44ca764772d3"
      },
      "source": [
        "# Training word2vec model\n",
        "from gensim.models import word2vec\n",
        "\n",
        "file_names = read_method.keys()\n",
        "data_sets = []\n",
        "for f in file_names:\n",
        "    data_sets.append(fetch_data(f))\n",
        "\n",
        "all_sents = []    \n",
        "all_intents = []\n",
        "for temp_sents,_,temp_intents in data_sets:\n",
        "    all_sents += list([list(x)+['EOS'] for x in temp_sents])\n",
        "    all_intents += list(temp_intents)\n",
        "    \n",
        "w2v_model = word2vec.Word2Vec(all_sents,min_count=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.train.w-intent.iob\n",
            "/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis-2.train.w-intent.iob\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycyszt6LHbw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from gensim.models import KeyedVectors\n",
        "# MODEL_PATH = '/home/b/Downloads/GoogleNews-vectors-negative300.bin.gz'\n",
        "# w2v_model = KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True,limit=2500000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghZ7_sZbHbxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_sentence(sent):\n",
        "    return [w2v_model.wv[word] for word in list(sent)+['EOS']]\n",
        "\n",
        "enc_sents = []\n",
        "exceptions = []\n",
        "for s in sents:\n",
        "    try:\n",
        "        enc_sents.append(embed_sentence(s))\n",
        "    except KeyError:\n",
        "        exceptions.append(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz65-oRzHbxc",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the intent labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3jSukKXHbxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2a76a1dd-451f-4388-e9a8-eb5b70d498a0"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "intent_encoder = preprocessing.LabelEncoder()\n",
        "intent_encoder.fit(all_intents)\n",
        "\n",
        "enc_intents = intent_encoder.transform(intents)\n",
        "\n",
        "target = torch.LongTensor(enc_intents).unsqueeze_(-1)\n",
        "\n",
        "pd.DataFrame({\"Intents\":intents[:5],\"Encoded Intents\":enc_intents[:5]})"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Intents</th>\n",
              "      <th>Encoded Intents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Intents  Encoded Intents\n",
              "0       atis_flight               14\n",
              "1       atis_flight               14\n",
              "2  atis_flight_time               19\n",
              "3      atis_airfare                3\n",
              "4      atis_airfare                3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6wz0qUhHbxm",
        "colab_type": "text"
      },
      "source": [
        "## Creating our sequential model (Bi-RNN) with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzovtibvHbxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.in2hid_fwd = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.in2hid_bck = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        \n",
        "        self.hid2out = nn.Linear(hidden_size*2, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "                    \n",
        "        hidden_fwd = self.initHidden()        \n",
        "        \n",
        "        for word in sentence:        \n",
        "            temp_comb = (torch.from_numpy(word).view(1,-1), hidden_fwd)\n",
        "            combined_fwd = torch.cat(temp_comb, 1)\n",
        "            hidden_fwd = self.in2hid_fwd(combined_fwd)\n",
        "        \n",
        "        hidden_bck = self.initHidden()        \n",
        "        \n",
        "        for word in sentence[::-1]:\n",
        "            temp_comb = (torch.from_numpy(word).view(1,-1), hidden_fwd)\n",
        "            combined_bck = torch.cat(temp_comb, 1)\n",
        "            hidden_bck = self.in2hid_bck(combined_bck)\n",
        "            \n",
        "        combined_full = torch.cat((hidden_fwd, hidden_bck), 1)\n",
        "        \n",
        "        output = self.hid2out(combined_full)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI8JWGMMHbxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RNN(input_size=w2v_model.vector_size,\n",
        "          hidden_size=50, \n",
        "          output_size=len(intent_encoder.classes_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFkrMv9qHbxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4e5ec63e-f24c-4aa8-ae9e-c5c085bcf242"
      },
      "source": [
        "learning_rate = 0.005 \n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "def train(sentence, intent):    \n",
        "    rnn.zero_grad()\n",
        "\n",
        "    output = rnn(sentence)\n",
        "    \n",
        "    loss = criterion(output, intent.long())\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "train(enc_sents[0],target[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-3.4511, -3.4708, -3.3146, -2.8499, -3.3338, -3.2680, -3.2497, -3.5036,\n",
              "          -3.2664, -3.1919, -3.4237, -3.1824, -3.4147, -3.3195, -3.3423, -3.3674,\n",
              "          -3.2611, -3.3482, -3.3405, -3.1272, -2.9243, -3.2798, -3.1616, -3.2516,\n",
              "          -3.2324, -3.1338]], grad_fn=<LogSoftmaxBackward>), 3.342261791229248)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQMlWp3Hbx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8efb0c01-f6d5-4bbc-fa12-66af96729938"
      },
      "source": [
        "import time\n",
        "import math\n",
        "total_loss = 0 \n",
        "n_iters = 2\n",
        "print_every = 1000\n",
        "all_losses = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    for x in range(len(enc_sents)):\n",
        "        output, loss = train(enc_sents[x],target[x])\n",
        "#         print (output,loss)\n",
        "        if math.isnan(x):\n",
        "            print (\"NAN loss\")\n",
        "            break\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "        if x % print_every == 0:\n",
        "            print('%.2fs since start | (Epoch : %d, %d%%) Loss : %.4f' % (time.time()-start, iter, iter / n_iters * 100, loss))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00s since start | (Epoch : 1, 50%) Loss : 3.2542\n",
            "1.87s since start | (Epoch : 1, 50%) Loss : 0.0854\n",
            "3.71s since start | (Epoch : 1, 50%) Loss : 0.3698\n",
            "5.52s since start | (Epoch : 1, 50%) Loss : 0.9056\n",
            "7.32s since start | (Epoch : 1, 50%) Loss : 0.0099\n",
            "9.09s since start | (Epoch : 2, 100%) Loss : 0.0420\n",
            "10.92s since start | (Epoch : 2, 100%) Loss : 0.0713\n",
            "12.72s since start | (Epoch : 2, 100%) Loss : 0.6056\n",
            "14.52s since start | (Epoch : 2, 100%) Loss : 0.1015\n",
            "16.31s since start | (Epoch : 2, 100%) Loss : 0.0689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIwmW43DHbyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d81a93ea-27f8-4f72-fd35-57ce92f80f85"
      },
      "source": [
        "def test_one(sent,val,allow=3):\n",
        "    pred = rnn(sent).topk(allow)[1].tolist()[0]\n",
        "    return val in pred\n",
        "\n",
        "def test():\n",
        "    sents_test,_,intents_test = fetch_data('/content/drive/NLP_book/Datasets/practicalnlp-master/Ch6/chatbot-code/data2/atis.test.w-intent.iob')\n",
        "    enc_intents_test = intent_encoder.transform(intents_test)\n",
        "    target_test = torch.LongTensor(enc_intents_test).unsqueeze_(-1)\n",
        "    \n",
        "    num_correct = 0.0\n",
        "    for sent,targ in zip(sents_test,target_test):\n",
        "        sent = embed_sentence(sent)    \n",
        "        if test_one(sent,targ,allow=1):\n",
        "            num_correct+=1\n",
        "            \n",
        "    print (\"Accuracy :\",num_correct/len(sents_test)*100)\n",
        "\n",
        "test()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 78.49944008958568\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}