{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.5"
    },
    "colab": {
      "name": "Word2vec_for_sentiment_classification (archived).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishkalavallabhi/practicalnlp/blob/V_2_0/Ch4/Word2vec_for_sentiment_classification%20(archived).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ONnX8MXl2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj5uPq5JFB6u",
        "colab_type": "code",
        "colab": {},
        "outputId": "177ca958-a0c2-4487-f3e1-905ee735b9ee"
      },
      "source": [
        "# load the google word2vec model this takes time and memory and hence it's wise to do it first and them move to other\n",
        "from gensim.models import KeyedVectors\n",
        "filename = '/content/drive/NLP_book/Datasets/practicalnlp-master/Ch4/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\inkpathak\\AppData\\Local\\Continuum\\anaconda2\\envs\\py34t\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
            "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbyYJkjBFB7G",
        "colab_type": "code",
        "colab": {},
        "outputId": "46c130b1-7248-47a7-aab4-79c51fad12e7"
      },
      "source": [
        "import csv\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections import Counter\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "import numpy as np \n",
        "import scipy as sp \n",
        "import matplotlib as mpl \n",
        "import matplotlib.cm as cm \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\inkpathak\\AppData\\Local\\Continuum\\anaconda2\\envs\\py34t\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLGNnMDXFB7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "senti_data = pd.DataFrame(columns = (\"Text\", \"Class\")) \n",
        "for cla in glob.glob(\"C:/Users/inkpathak/Desktop/Anuj Gupta/Word2vec/txt_sentoken/*\"): # Here the folder name is data set in which there are two sub-folder \"Spam\" & \"Ham\"\n",
        "    clas = cla.split(os.sep)[1]    # We are splitting the folder names as class using OS-Seperator and taking the 2nd item in the list\n",
        "    for file in glob.glob(cla + \"/*.txt\"): # Here we are deep diving in each of the folder and reading the text files one by one\n",
        "        text = open(file, \"r\", encoding = \"ISO-8859-1\").read() # Reading the file , for Windows generally we need to mention the encoding \n",
        "        text = \" \".join(text.split(\"\\n\")) # Splitting the text files and rejoining into a single text\n",
        "        senti_data = senti_data.append(pd.Series([text, clas], index = [\"Text\", \"Class\"]), ignore_index = True) # continious append to the data frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVnuRApKFB7P",
        "colab_type": "code",
        "colab": {},
        "outputId": "1c1cc740-0a31-4b5f-c6c0-35eab509eef3"
      },
      "source": [
        "senti_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review  damn t...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Class\n",
              "0  plot : two teen couples go to a church party ,...   neg\n",
              "1  the happy bastard's quick movie review  damn t...   neg\n",
              "2  it is movies like these that make a jaded movi...   neg\n",
              "3   \" quest for camelot \" is warner bros . ' firs...   neg\n",
              "4  synopsis : a mentally unstable man undergoing ...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkWbXMtQFB7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert label to a numerical variable\n",
        "senti_data['Class'] = senti_data.Class.map({'neg':0, 'pos':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGklaToIFB8b",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c569beb-548a-49f5-c837-ded20282c951"
      },
      "source": [
        "senti_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review  damn t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Class\n",
              "0  plot : two teen couples go to a church party ,...      0\n",
              "1  the happy bastard's quick movie review  damn t...      0\n",
              "2  it is movies like these that make a jaded movi...      0\n",
              "3   \" quest for camelot \" is warner bros . ' firs...      0\n",
              "4  synopsis : a mentally unstable man undergoing ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lzgfXY1FB-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAy_OHYgFB-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(doc):\n",
        "    doc = \" \".join([i.replace('*', '') for i in doc.lower().split()])\n",
        "    doc = \" \".join([i.replace(':', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('.', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('=', '') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('/', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace(')', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('(', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('\"', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('-', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i.replace('_', ' ') for i in doc.split()])\n",
        "    doc = \" \".join([i for i in doc.split() if not i.isdigit()])\n",
        "    doc = \" \".join([i for i in doc.split() if i.isalpha()])\n",
        "    doc = \" \".join([i for i in doc.split() if i not in stop])\n",
        "    return doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Efq2fEqFB-3",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfaddb05-c7ac-4131-c496-19023ce13f06"
      },
      "source": [
        "review_clear = [clean(doc) for doc in senti_data['Text']]\n",
        "senti_data['clean_text']=review_clear\n",
        "senti_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>plot two teen couples go church party drink dr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review  damn t...</td>\n",
              "      <td>0</td>\n",
              "      <td>happy quick movie review damn bug got head sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "      <td>movies like make jaded movie viewer thankful i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "      <td>quest camelot warner bros first feature length...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "      <td>synopsis mentally unstable man undergoing psyc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Class  \\\n",
              "0  plot : two teen couples go to a church party ,...      0   \n",
              "1  the happy bastard's quick movie review  damn t...      0   \n",
              "2  it is movies like these that make a jaded movi...      0   \n",
              "3   \" quest for camelot \" is warner bros . ' firs...      0   \n",
              "4  synopsis : a mentally unstable man undergoing ...      0   \n",
              "\n",
              "                                          clean_text  \n",
              "0  plot two teen couples go church party drink dr...  \n",
              "1  happy quick movie review damn bug got head sta...  \n",
              "2  movies like make jaded movie viewer thankful i...  \n",
              "3  quest camelot warner bros first feature length...  \n",
              "4  synopsis mentally unstable man undergoing psyc...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKIVC2guFB--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build sentense vecto for training set by using the total value of all word vectors in the Clean text column\n",
        "\n",
        "def buildSentenceVector(text):\n",
        "    sent_vec = np.zeros(300).reshape((1, 300))\n",
        "    count = 0.\n",
        "    for word in text:\n",
        "        try:\n",
        "            sent_vec += model[word].reshape((1, 300))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    #if count != 0:\n",
        "    #    sent_vec /= count\n",
        "    return sent_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk3g3vGfFB_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_vec = [buildSentenceVector(doc) for doc in senti_data['clean_text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_jhaCrXFB_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "senti_data['sentense_vector']=review_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fbRrCj-FB_c",
        "colab_type": "code",
        "colab": {},
        "outputId": "244c27bc-7eff-48b6-c21e-6ecf838eac7f"
      },
      "source": [
        "senti_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentense_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>plot two teen couples go church party drink dr...</td>\n",
              "      <td>[[-293.95513916015625, 192.2789306640625, -4.9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review  damn t...</td>\n",
              "      <td>0</td>\n",
              "      <td>happy quick movie review damn bug got head sta...</td>\n",
              "      <td>[[-112.78167724609375, 65.20263671875, 0.33660...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "      <td>movies like make jaded movie viewer thankful i...</td>\n",
              "      <td>[[-242.486083984375, 163.73614501953125, 0.711...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "      <td>quest camelot warner bros first feature length...</td>\n",
              "      <td>[[-250.0531005859375, 168.8553466796875, -4.26...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "      <td>synopsis mentally unstable man undergoing psyc...</td>\n",
              "      <td>[[-378.0009765625, 267.97918701171875, 1.84680...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Class  \\\n",
              "0  plot : two teen couples go to a church party ,...      0   \n",
              "1  the happy bastard's quick movie review  damn t...      0   \n",
              "2  it is movies like these that make a jaded movi...      0   \n",
              "3   \" quest for camelot \" is warner bros . ' firs...      0   \n",
              "4  synopsis : a mentally unstable man undergoing ...      0   \n",
              "\n",
              "                                          clean_text  \\\n",
              "0  plot two teen couples go church party drink dr...   \n",
              "1  happy quick movie review damn bug got head sta...   \n",
              "2  movies like make jaded movie viewer thankful i...   \n",
              "3  quest camelot warner bros first feature length...   \n",
              "4  synopsis mentally unstable man undergoing psyc...   \n",
              "\n",
              "                                     sentense_vector  \n",
              "0  [[-293.95513916015625, 192.2789306640625, -4.9...  \n",
              "1  [[-112.78167724609375, 65.20263671875, 0.33660...  \n",
              "2  [[-242.486083984375, 163.73614501953125, 0.711...  \n",
              "3  [[-250.0531005859375, 168.8553466796875, -4.26...  \n",
              "4  [[-378.0009765625, 267.97918701171875, 1.84680...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve0jgq0-FCAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_vec1 = [i[0] for i in review_vec] # changing from list of list to single list\n",
        "review_vec2 = np.array(review_vec1) # Changing from single list to array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_MghjBOFCAL",
        "colab_type": "code",
        "colab": {},
        "outputId": "4c5cbf4b-7aa9-4577-d170-c7b45adc9b76"
      },
      "source": [
        "review_vec2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rng1KDIFCAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_df = pd.DataFrame(review_vec2) # changinf the array to a dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYzCjVJBFCAd",
        "colab_type": "code",
        "colab": {},
        "outputId": "47234ff6-1de2-4057-972d-42ccfaf73ce7"
      },
      "source": [
        "review_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-293.955139</td>\n",
              "      <td>192.278931</td>\n",
              "      <td>-4.972412</td>\n",
              "      <td>246.479492</td>\n",
              "      <td>-76.376129</td>\n",
              "      <td>52.847504</td>\n",
              "      <td>-149.930115</td>\n",
              "      <td>-68.620850</td>\n",
              "      <td>-81.728027</td>\n",
              "      <td>26.597717</td>\n",
              "      <td>...</td>\n",
              "      <td>116.883545</td>\n",
              "      <td>-33.414062</td>\n",
              "      <td>-166.789688</td>\n",
              "      <td>156.874390</td>\n",
              "      <td>-55.962769</td>\n",
              "      <td>-263.559921</td>\n",
              "      <td>-162.363647</td>\n",
              "      <td>-40.535278</td>\n",
              "      <td>-190.335449</td>\n",
              "      <td>264.554199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-112.781677</td>\n",
              "      <td>65.202637</td>\n",
              "      <td>0.336609</td>\n",
              "      <td>92.041504</td>\n",
              "      <td>-27.368500</td>\n",
              "      <td>18.075989</td>\n",
              "      <td>-55.470612</td>\n",
              "      <td>-36.053345</td>\n",
              "      <td>-30.213440</td>\n",
              "      <td>6.324829</td>\n",
              "      <td>...</td>\n",
              "      <td>41.426025</td>\n",
              "      <td>2.624512</td>\n",
              "      <td>-56.628387</td>\n",
              "      <td>61.097534</td>\n",
              "      <td>-24.956787</td>\n",
              "      <td>-102.484375</td>\n",
              "      <td>-68.589966</td>\n",
              "      <td>-16.991699</td>\n",
              "      <td>-71.407837</td>\n",
              "      <td>101.894714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-242.486084</td>\n",
              "      <td>163.736145</td>\n",
              "      <td>0.711853</td>\n",
              "      <td>198.322754</td>\n",
              "      <td>-68.430664</td>\n",
              "      <td>43.944977</td>\n",
              "      <td>-130.381378</td>\n",
              "      <td>-61.356079</td>\n",
              "      <td>-73.543579</td>\n",
              "      <td>25.141663</td>\n",
              "      <td>...</td>\n",
              "      <td>109.481201</td>\n",
              "      <td>-21.978760</td>\n",
              "      <td>-149.334961</td>\n",
              "      <td>124.054443</td>\n",
              "      <td>-40.955688</td>\n",
              "      <td>-225.843277</td>\n",
              "      <td>-138.615723</td>\n",
              "      <td>-27.549072</td>\n",
              "      <td>-161.180542</td>\n",
              "      <td>220.218445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-250.053101</td>\n",
              "      <td>168.855347</td>\n",
              "      <td>-4.266174</td>\n",
              "      <td>195.756836</td>\n",
              "      <td>-72.587067</td>\n",
              "      <td>44.229919</td>\n",
              "      <td>-127.833618</td>\n",
              "      <td>-64.556030</td>\n",
              "      <td>-76.520386</td>\n",
              "      <td>25.055115</td>\n",
              "      <td>...</td>\n",
              "      <td>100.104736</td>\n",
              "      <td>-21.081909</td>\n",
              "      <td>-139.455933</td>\n",
              "      <td>126.582520</td>\n",
              "      <td>-42.903931</td>\n",
              "      <td>-221.102890</td>\n",
              "      <td>-135.423828</td>\n",
              "      <td>-37.146851</td>\n",
              "      <td>-160.887817</td>\n",
              "      <td>230.279663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-378.000977</td>\n",
              "      <td>267.979187</td>\n",
              "      <td>1.846802</td>\n",
              "      <td>302.576904</td>\n",
              "      <td>-102.295349</td>\n",
              "      <td>59.879395</td>\n",
              "      <td>-188.510895</td>\n",
              "      <td>-105.857422</td>\n",
              "      <td>-103.271912</td>\n",
              "      <td>29.568604</td>\n",
              "      <td>...</td>\n",
              "      <td>149.544434</td>\n",
              "      <td>-43.593750</td>\n",
              "      <td>-232.855728</td>\n",
              "      <td>211.853516</td>\n",
              "      <td>-71.249023</td>\n",
              "      <td>-353.665085</td>\n",
              "      <td>-206.748779</td>\n",
              "      <td>-61.833618</td>\n",
              "      <td>-227.511963</td>\n",
              "      <td>374.038635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0           1         2           3           4          5    \\\n",
              "0 -293.955139  192.278931 -4.972412  246.479492  -76.376129  52.847504   \n",
              "1 -112.781677   65.202637  0.336609   92.041504  -27.368500  18.075989   \n",
              "2 -242.486084  163.736145  0.711853  198.322754  -68.430664  43.944977   \n",
              "3 -250.053101  168.855347 -4.266174  195.756836  -72.587067  44.229919   \n",
              "4 -378.000977  267.979187  1.846802  302.576904 -102.295349  59.879395   \n",
              "\n",
              "          6           7           8          9       ...             290  \\\n",
              "0 -149.930115  -68.620850  -81.728027  26.597717     ...      116.883545   \n",
              "1  -55.470612  -36.053345  -30.213440   6.324829     ...       41.426025   \n",
              "2 -130.381378  -61.356079  -73.543579  25.141663     ...      109.481201   \n",
              "3 -127.833618  -64.556030  -76.520386  25.055115     ...      100.104736   \n",
              "4 -188.510895 -105.857422 -103.271912  29.568604     ...      149.544434   \n",
              "\n",
              "         291         292         293        294         295         296  \\\n",
              "0 -33.414062 -166.789688  156.874390 -55.962769 -263.559921 -162.363647   \n",
              "1   2.624512  -56.628387   61.097534 -24.956787 -102.484375  -68.589966   \n",
              "2 -21.978760 -149.334961  124.054443 -40.955688 -225.843277 -138.615723   \n",
              "3 -21.081909 -139.455933  126.582520 -42.903931 -221.102890 -135.423828   \n",
              "4 -43.593750 -232.855728  211.853516 -71.249023 -353.665085 -206.748779   \n",
              "\n",
              "         297         298         299  \n",
              "0 -40.535278 -190.335449  264.554199  \n",
              "1 -16.991699  -71.407837  101.894714  \n",
              "2 -27.549072 -161.180542  220.218445  \n",
              "3 -37.146851 -160.887817  230.279663  \n",
              "4 -61.833618 -227.511963  374.038635  \n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q-VaFSCFCAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_df[\"sentiment\"] = senti_data[\"Class\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5yRMIauFCBK",
        "colab_type": "code",
        "colab": {},
        "outputId": "e775050e-5459-4f76-cd96-f4e781af155d"
      },
      "source": [
        "review_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-293.955139</td>\n",
              "      <td>192.278931</td>\n",
              "      <td>-4.972412</td>\n",
              "      <td>246.479492</td>\n",
              "      <td>-76.376129</td>\n",
              "      <td>52.847504</td>\n",
              "      <td>-149.930115</td>\n",
              "      <td>-68.620850</td>\n",
              "      <td>-81.728027</td>\n",
              "      <td>26.597717</td>\n",
              "      <td>...</td>\n",
              "      <td>-33.414062</td>\n",
              "      <td>-166.789688</td>\n",
              "      <td>156.874390</td>\n",
              "      <td>-55.962769</td>\n",
              "      <td>-263.559921</td>\n",
              "      <td>-162.363647</td>\n",
              "      <td>-40.535278</td>\n",
              "      <td>-190.335449</td>\n",
              "      <td>264.554199</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-112.781677</td>\n",
              "      <td>65.202637</td>\n",
              "      <td>0.336609</td>\n",
              "      <td>92.041504</td>\n",
              "      <td>-27.368500</td>\n",
              "      <td>18.075989</td>\n",
              "      <td>-55.470612</td>\n",
              "      <td>-36.053345</td>\n",
              "      <td>-30.213440</td>\n",
              "      <td>6.324829</td>\n",
              "      <td>...</td>\n",
              "      <td>2.624512</td>\n",
              "      <td>-56.628387</td>\n",
              "      <td>61.097534</td>\n",
              "      <td>-24.956787</td>\n",
              "      <td>-102.484375</td>\n",
              "      <td>-68.589966</td>\n",
              "      <td>-16.991699</td>\n",
              "      <td>-71.407837</td>\n",
              "      <td>101.894714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-242.486084</td>\n",
              "      <td>163.736145</td>\n",
              "      <td>0.711853</td>\n",
              "      <td>198.322754</td>\n",
              "      <td>-68.430664</td>\n",
              "      <td>43.944977</td>\n",
              "      <td>-130.381378</td>\n",
              "      <td>-61.356079</td>\n",
              "      <td>-73.543579</td>\n",
              "      <td>25.141663</td>\n",
              "      <td>...</td>\n",
              "      <td>-21.978760</td>\n",
              "      <td>-149.334961</td>\n",
              "      <td>124.054443</td>\n",
              "      <td>-40.955688</td>\n",
              "      <td>-225.843277</td>\n",
              "      <td>-138.615723</td>\n",
              "      <td>-27.549072</td>\n",
              "      <td>-161.180542</td>\n",
              "      <td>220.218445</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-250.053101</td>\n",
              "      <td>168.855347</td>\n",
              "      <td>-4.266174</td>\n",
              "      <td>195.756836</td>\n",
              "      <td>-72.587067</td>\n",
              "      <td>44.229919</td>\n",
              "      <td>-127.833618</td>\n",
              "      <td>-64.556030</td>\n",
              "      <td>-76.520386</td>\n",
              "      <td>25.055115</td>\n",
              "      <td>...</td>\n",
              "      <td>-21.081909</td>\n",
              "      <td>-139.455933</td>\n",
              "      <td>126.582520</td>\n",
              "      <td>-42.903931</td>\n",
              "      <td>-221.102890</td>\n",
              "      <td>-135.423828</td>\n",
              "      <td>-37.146851</td>\n",
              "      <td>-160.887817</td>\n",
              "      <td>230.279663</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-378.000977</td>\n",
              "      <td>267.979187</td>\n",
              "      <td>1.846802</td>\n",
              "      <td>302.576904</td>\n",
              "      <td>-102.295349</td>\n",
              "      <td>59.879395</td>\n",
              "      <td>-188.510895</td>\n",
              "      <td>-105.857422</td>\n",
              "      <td>-103.271912</td>\n",
              "      <td>29.568604</td>\n",
              "      <td>...</td>\n",
              "      <td>-43.593750</td>\n",
              "      <td>-232.855728</td>\n",
              "      <td>211.853516</td>\n",
              "      <td>-71.249023</td>\n",
              "      <td>-353.665085</td>\n",
              "      <td>-206.748779</td>\n",
              "      <td>-61.833618</td>\n",
              "      <td>-227.511963</td>\n",
              "      <td>374.038635</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 301 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1         2           3           4          5  \\\n",
              "0 -293.955139  192.278931 -4.972412  246.479492  -76.376129  52.847504   \n",
              "1 -112.781677   65.202637  0.336609   92.041504  -27.368500  18.075989   \n",
              "2 -242.486084  163.736145  0.711853  198.322754  -68.430664  43.944977   \n",
              "3 -250.053101  168.855347 -4.266174  195.756836  -72.587067  44.229919   \n",
              "4 -378.000977  267.979187  1.846802  302.576904 -102.295349  59.879395   \n",
              "\n",
              "            6           7           8          9    ...            291  \\\n",
              "0 -149.930115  -68.620850  -81.728027  26.597717    ...     -33.414062   \n",
              "1  -55.470612  -36.053345  -30.213440   6.324829    ...       2.624512   \n",
              "2 -130.381378  -61.356079  -73.543579  25.141663    ...     -21.978760   \n",
              "3 -127.833618  -64.556030  -76.520386  25.055115    ...     -21.081909   \n",
              "4 -188.510895 -105.857422 -103.271912  29.568604    ...     -43.593750   \n",
              "\n",
              "          292         293        294         295         296        297  \\\n",
              "0 -166.789688  156.874390 -55.962769 -263.559921 -162.363647 -40.535278   \n",
              "1  -56.628387   61.097534 -24.956787 -102.484375  -68.589966 -16.991699   \n",
              "2 -149.334961  124.054443 -40.955688 -225.843277 -138.615723 -27.549072   \n",
              "3 -139.455933  126.582520 -42.903931 -221.102890 -135.423828 -37.146851   \n",
              "4 -232.855728  211.853516 -71.249023 -353.665085 -206.748779 -61.833618   \n",
              "\n",
              "          298         299  sentiment  \n",
              "0 -190.335449  264.554199          0  \n",
              "1  -71.407837  101.894714          0  \n",
              "2 -161.180542  220.218445          0  \n",
              "3 -160.887817  230.279663          0  \n",
              "4 -227.511963  374.038635          0  \n",
              "\n",
              "[5 rows x 301 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_Go5PeFCBS",
        "colab_type": "code",
        "colab": {},
        "outputId": "58a71cd6-d765-42f8-fd92-f4c40cdfc0ac"
      },
      "source": [
        "X = review_df.iloc[:,0:300]\n",
        "y = review_df.sentiment\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 300)\n",
            "(2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orJwIXKFCBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scale X here by each row\n",
        "from sklearn.preprocessing import scale\n",
        "X= scale(X, axis=1, with_mean=True, with_std=True, copy=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDE1t5FeFCB9",
        "colab_type": "code",
        "colab": {},
        "outputId": "623d7b71-52d9-4b06-b16e-343bca03394b"
      },
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 300)\n",
            "(500, 300)\n",
            "(1500,)\n",
            "(500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd-kDuW4FCCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. import\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 2. instantiate a logistic regression model\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNNovRMaFCCi",
        "colab_type": "code",
        "colab": {},
        "outputId": "d81bcd52-f7b5-4275-ec0e-c44ee73b2888"
      },
      "source": [
        "%time logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 622 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_7gXEMFCC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_class = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xj9QibkFCDF",
        "colab_type": "code",
        "colab": {},
        "outputId": "29f238b6-4df8-4730-f770-b9c99fc39841"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXNJG3rBFCDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_prob = logreg.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ_tnwHmFCDh",
        "colab_type": "code",
        "colab": {},
        "outputId": "f06124e7-98a9-4504-e200-86592755dad6"
      },
      "source": [
        "metrics.confusion_matrix(y_test, y_pred_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[165,  90],\n",
              "       [116, 129]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g4LZupdFCEz",
        "colab_type": "code",
        "colab": {},
        "outputId": "5c177298-16de-43c3-e596-e9b9b18fb286"
      },
      "source": [
        "# Checking how many words are there in google Word to vec \n",
        "word2vec_vocab = model.vocab.keys()\n",
        "word2vec_vocab_lower = [item.lower() for item in word2vec_vocab]\n",
        "\n",
        "print(len(word2vec_vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tahl3x8RFCE4",
        "colab_type": "code",
        "colab": {},
        "outputId": "f83880e9-48d3-4e09-947d-496b4cdf2223"
      },
      "source": [
        "senti_data[\"clean_text\"][4].split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synopsis',\n",
              " 'mentally',\n",
              " 'unstable',\n",
              " 'man',\n",
              " 'undergoing',\n",
              " 'psychotherapy',\n",
              " 'saves',\n",
              " 'boy',\n",
              " 'potentially',\n",
              " 'fatal',\n",
              " 'accident',\n",
              " 'falls',\n",
              " 'love',\n",
              " 'mother',\n",
              " 'fledgling',\n",
              " 'restauranteur',\n",
              " 'unsuccessfully',\n",
              " 'attempting',\n",
              " 'gain',\n",
              " 'favor',\n",
              " 'takes',\n",
              " 'pictures',\n",
              " 'kills',\n",
              " 'number',\n",
              " 'people',\n",
              " 'way',\n",
              " 'comments',\n",
              " 'stalked',\n",
              " 'yet',\n",
              " 'another',\n",
              " 'seemingly',\n",
              " 'endless',\n",
              " 'string',\n",
              " 'spurned',\n",
              " 'psychos',\n",
              " 'getting',\n",
              " 'revenge',\n",
              " 'type',\n",
              " 'movies',\n",
              " 'stable',\n",
              " 'category',\n",
              " 'film',\n",
              " 'industry',\n",
              " 'theatrical',\n",
              " 'direct',\n",
              " 'video',\n",
              " 'proliferation',\n",
              " 'may',\n",
              " 'due',\n",
              " 'part',\n",
              " 'fact',\n",
              " 'typically',\n",
              " 'inexpensive',\n",
              " 'produce',\n",
              " 'special',\n",
              " 'effects',\n",
              " 'big',\n",
              " 'name',\n",
              " 'stars',\n",
              " 'serve',\n",
              " 'vehicles',\n",
              " 'flash',\n",
              " 'nudity',\n",
              " 'allowing',\n",
              " 'frequent',\n",
              " 'late',\n",
              " 'night',\n",
              " 'cable',\n",
              " 'television',\n",
              " 'stalked',\n",
              " 'wavers',\n",
              " 'slightly',\n",
              " 'norm',\n",
              " 'one',\n",
              " 'respect',\n",
              " 'psycho',\n",
              " 'never',\n",
              " 'actually',\n",
              " 'affair',\n",
              " 'contrary',\n",
              " 'rejected',\n",
              " 'rather',\n",
              " 'quickly',\n",
              " 'psycho',\n",
              " 'typically',\n",
              " 'ex',\n",
              " 'lover',\n",
              " 'ex',\n",
              " 'wife',\n",
              " 'ex',\n",
              " 'husband',\n",
              " 'stalked',\n",
              " 'another',\n",
              " 'redundant',\n",
              " 'entry',\n",
              " 'doomed',\n",
              " 'collect',\n",
              " 'dust',\n",
              " 'video',\n",
              " 'shelves',\n",
              " 'viewed',\n",
              " 'midnight',\n",
              " 'cable',\n",
              " 'stalked',\n",
              " 'provide',\n",
              " 'much',\n",
              " 'suspense',\n",
              " 'though',\n",
              " 'sets',\n",
              " 'interspersed',\n",
              " 'throughout',\n",
              " 'opening',\n",
              " 'credits',\n",
              " 'instance',\n",
              " 'serious',\n",
              " 'sounding',\n",
              " 'narrator',\n",
              " 'spouts',\n",
              " 'statistics',\n",
              " 'stalkers',\n",
              " 'ponders',\n",
              " 'may',\n",
              " 'cause',\n",
              " 'man',\n",
              " 'stalk',\n",
              " 'implicitly',\n",
              " 'implied',\n",
              " 'stalkers',\n",
              " 'men',\n",
              " 'pictures',\n",
              " 'boy',\n",
              " 'shown',\n",
              " 'screen',\n",
              " 'credits',\n",
              " 'snapshot',\n",
              " 'actor',\n",
              " 'jay',\n",
              " 'underwood',\n",
              " 'appears',\n",
              " 'narrator',\n",
              " 'states',\n",
              " 'story',\n",
              " 'daryl',\n",
              " 'gleason',\n",
              " 'tells',\n",
              " 'audience',\n",
              " 'stalker',\n",
              " 'course',\n",
              " 'really',\n",
              " 'story',\n",
              " 'restauranteur',\n",
              " 'brooke',\n",
              " 'daniels',\n",
              " 'movie',\n",
              " 'meant',\n",
              " 'daryl',\n",
              " 'called',\n",
              " 'stalker',\n",
              " 'stalked',\n",
              " 'okay',\n",
              " 'know',\n",
              " 'stalker',\n",
              " 'even',\n",
              " 'movie',\n",
              " 'starts',\n",
              " 'guesswork',\n",
              " 'required',\n",
              " 'stalked',\n",
              " 'proceeds',\n",
              " 'begins',\n",
              " 'obvious',\n",
              " 'obvious',\n",
              " 'obvious',\n",
              " 'opening',\n",
              " 'sequence',\n",
              " 'contrived',\n",
              " 'quite',\n",
              " 'bit',\n",
              " 'brings',\n",
              " 'daryl',\n",
              " 'brooke',\n",
              " 'victim',\n",
              " 'together',\n",
              " 'daryl',\n",
              " 'obsesses',\n",
              " 'brooke',\n",
              " 'follows',\n",
              " 'around',\n",
              " 'tries',\n",
              " 'woo',\n",
              " 'ultimately',\n",
              " 'rejected',\n",
              " 'plans',\n",
              " 'become',\n",
              " 'desperate',\n",
              " 'elaborate',\n",
              " 'plans',\n",
              " 'include',\n",
              " 'time',\n",
              " 'psycho',\n",
              " 'love',\n",
              " 'cliche',\n",
              " 'murdered',\n",
              " 'pet',\n",
              " 'reason',\n",
              " 'films',\n",
              " 'require',\n",
              " 'dead',\n",
              " 'pet',\n",
              " 'found',\n",
              " 'victim',\n",
              " 'stalked',\n",
              " 'stalked',\n",
              " 'exception',\n",
              " 'cat',\n",
              " 'time',\n",
              " 'found',\n",
              " 'shower',\n",
              " 'events',\n",
              " 'like',\n",
              " 'lead',\n",
              " 'inevitable',\n",
              " 'showdown',\n",
              " 'stalker',\n",
              " 'stalked',\n",
              " 'one',\n",
              " 'survives',\n",
              " 'guess',\n",
              " 'invariably',\n",
              " 'always',\n",
              " 'guess',\n",
              " 'conclusion',\n",
              " 'turkey',\n",
              " 'cast',\n",
              " 'uniformly',\n",
              " 'adequate',\n",
              " 'anything',\n",
              " 'write',\n",
              " 'home',\n",
              " 'also',\n",
              " 'bad',\n",
              " 'either',\n",
              " 'jay',\n",
              " 'underwood',\n",
              " 'stalker',\n",
              " 'turns',\n",
              " 'toward',\n",
              " 'melodrama',\n",
              " 'bit',\n",
              " 'much',\n",
              " 'overdoes',\n",
              " 'words',\n",
              " 'still',\n",
              " 'manages',\n",
              " 'creepy',\n",
              " 'enough',\n",
              " 'pass',\n",
              " 'type',\n",
              " 'stalker',\n",
              " 'story',\n",
              " 'demands',\n",
              " 'maryam',\n",
              " 'actor',\n",
              " 'close',\n",
              " 'star',\n",
              " 'played',\n",
              " 'bond',\n",
              " 'chick',\n",
              " 'living',\n",
              " 'daylights',\n",
              " 'equally',\n",
              " 'adequate',\n",
              " 'stalked',\n",
              " 'title',\n",
              " 'even',\n",
              " 'though',\n",
              " 'seems',\n",
              " 'ditzy',\n",
              " 'times',\n",
              " 'strong',\n",
              " 'independent',\n",
              " 'business',\n",
              " 'owner',\n",
              " 'brooke',\n",
              " 'needs',\n",
              " 'ditzy',\n",
              " 'however',\n",
              " 'plot',\n",
              " 'proceed',\n",
              " 'toward',\n",
              " 'end',\n",
              " 'example',\n",
              " 'brooke',\n",
              " 'suspicions',\n",
              " 'daryl',\n",
              " 'ensure',\n",
              " 'use',\n",
              " 'another',\n",
              " 'excuse',\n",
              " 'see',\n",
              " 'brooke',\n",
              " 'decides',\n",
              " 'return',\n",
              " 'toolbox',\n",
              " 'left',\n",
              " 'place',\n",
              " 'house',\n",
              " 'leave',\n",
              " 'toolbox',\n",
              " 'door',\n",
              " 'one',\n",
              " 'answers',\n",
              " 'course',\n",
              " 'tries',\n",
              " 'door',\n",
              " 'opens',\n",
              " 'wanders',\n",
              " 'around',\n",
              " 'house',\n",
              " 'daryl',\n",
              " 'returns',\n",
              " 'enters',\n",
              " 'house',\n",
              " 'course',\n",
              " 'heroine',\n",
              " 'danger',\n",
              " 'somehow',\n",
              " 'even',\n",
              " 'though',\n",
              " 'car',\n",
              " 'parked',\n",
              " 'front',\n",
              " 'house',\n",
              " 'right',\n",
              " 'front',\n",
              " 'door',\n",
              " 'daryl',\n",
              " 'oblivious',\n",
              " 'presence',\n",
              " 'inside',\n",
              " 'whole',\n",
              " 'episode',\n",
              " 'places',\n",
              " 'incredible',\n",
              " 'strain',\n",
              " 'suspension',\n",
              " 'disbelief',\n",
              " 'questions',\n",
              " 'validity',\n",
              " 'either',\n",
              " 'intelligence',\n",
              " 'stalked',\n",
              " 'receives',\n",
              " 'two',\n",
              " 'stars',\n",
              " 'even',\n",
              " 'though',\n",
              " 'highly',\n",
              " 'derivative',\n",
              " 'somewhat',\n",
              " 'boring',\n",
              " 'bad',\n",
              " 'cannot',\n",
              " 'watched',\n",
              " 'rated',\n",
              " 'r',\n",
              " 'mostly',\n",
              " 'several',\n",
              " 'murder',\n",
              " 'scenes',\n",
              " 'brief',\n",
              " 'nudity',\n",
              " 'strip',\n",
              " 'bar',\n",
              " 'offensive',\n",
              " 'many',\n",
              " 'thrillers',\n",
              " 'genre',\n",
              " 'mood',\n",
              " 'good',\n",
              " 'suspense',\n",
              " 'film',\n",
              " 'though',\n",
              " 'stake',\n",
              " 'something',\n",
              " 'else']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1eKvNqgFCFB",
        "colab_type": "code",
        "colab": {},
        "outputId": "b558485d-0fef-426f-919c-990d605a9e13"
      },
      "source": [
        "senti_data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVhuacfVFCFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = []\n",
        "for i in range(senti_data.shape[0]):\n",
        "    kk=senti_data[\"clean_text\"][i].split()\n",
        "    word_list.append(kk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "418UJk7VFCFV",
        "colab_type": "code",
        "colab": {},
        "outputId": "583b5ad7-370e-4464-ea91-45c3b4721b91"
      },
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vta5JaKvFCGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = [item for sublist in word_list for item in sublist] unlisting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cqxim2XFCGu",
        "colab_type": "code",
        "colab": {},
        "outputId": "0c548c35-1625-417a-938d-0ce191a6c2c9"
      },
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl-fvithFCG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "unique_words = list(set(word_list))  #this will give unique list of words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abR4ralFCG9",
        "colab_type": "code",
        "colab": {},
        "outputId": "3acd549b-c81a-42e2-e019-e38509ef57aa"
      },
      "source": [
        "print(len(unique_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkvJlmM_FCHK",
        "colab_type": "code",
        "colab": {},
        "outputId": "e8b6b365-9498-4918-fa30-e439270a29fe"
      },
      "source": [
        "kk=0\n",
        "for word in unique_words:\n",
        "    try:\n",
        "        \n",
        "        kp= model[word]\n",
        "        kk +=1\n",
        "    except KeyError:\n",
        "        continue\n",
        "print(kk) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_fvYplpFCHp",
        "colab_type": "code",
        "colab": {},
        "outputId": "5f77ea10-9567-4231-b354-d79f514b1ef1"
      },
      "source": [
        "print(kk/len(unique_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8210680092870373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIpcetQhFCH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}